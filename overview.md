# LLM Router - Vue d'ensemble

## Objectif

SystÃ¨me de routage intelligent qui choisit dynamiquement le meilleur modÃ¨le LLM pour chaque requÃªte selon le contexte, tout en optimisant coÃ»t et latence.

## Architecture par composants

```
llm-router/
â”œâ”€â”€ README.md                # DÃ©marrage rapide
â”œâ”€â”€ overview.md              # Ce fichier - vision globale
â”œâ”€â”€ routing-engine.md        # Moteur de dÃ©cision (keywords â†’ LLM)
â”œâ”€â”€ model-calls.md           # Gestion des appels aux LLMs cibles
â”œâ”€â”€ fallback-guardrails.md   # Fallbacks et sÃ©curitÃ©s
â”œâ”€â”€ monitoring.md            # Cost/latence/metrics
â”œâ”€â”€ integration.md           # Plugin OpenClaw (config provider)
â””â”€â”€ service/
    â”œâ”€â”€ main.py              # Service FastAPI
    â”œâ”€â”€ requirements.txt     # DÃ©pendances
    â””â”€â”€ .env.example         # Config
```

## Phases de dÃ©veloppement

| Phase | Description | Status |
|-------|-------------|--------|
| Phase 1 | Forward-only vers OpenRouter | âœ… |
| Phase 2 | Routing par keywords + monitoring | âœ… |
| Phase 3 | Router LLM-based (Qwen local) | ðŸ”œ |

## DÃ©cisions d'architecture

| Sujet | DÃ©cision | Status |
|-------|----------|--------|
| Scope | Par requÃªte avec continuitÃ© intelligente | âœ… |
| Router Phase 2 | Keywords/rÃ¨gles simples | âœ… |
| Router Phase 3 | LLM (Qwen local ou API) | ðŸ”œ |
| Contexte | Dernier message utilisateur | âœ… |
| IntÃ©gration | Provider custom OpenClaw | âœ… |
| Support tools | DÃ©tection + routing spÃ©cialisÃ© | âœ… |

## CatÃ©gories de routing (Phase 2)

| CatÃ©gorie | DÃ©tection | ModÃ¨les |
|-----------|-----------|---------|
| **tools** | `request.tools` prÃ©sent | aurora-alpha â†’ kimi-k2.5 â†’ glm-5 |
| **code** | keywords: python, function, debug, api... | glm-5 â†’ aurora-alpha â†’ gpt-4o-mini |
| **reasoning** | keywords: why, how, explain, analyze... | aurora-alpha â†’ glm-5 â†’ kimi-k2.5 |
| **conversation** | messages courts, hello, thanks... | glm-5 â†’ gpt-4o-mini â†’ aurora-alpha |

## IntÃ©gration OpenClaw

Le router est configurÃ© comme un provider custom:

```json
{
  "providers": {
    "router": {
      "baseUrl": "http://localhost:3456",
      "api": "openai-completions",
      "models": [{ "id": "router" }]
    }
  }
}
```

Le modÃ¨le primaire est `router/router` dans la config OpenClaw.

## DÃ©ploiement

- **Local**: `uvicorn main:app --port 3456`
- **Port**: 3456
- **Provider cible**: OpenRouter

## Prochaines Ã©tapes

1. ImplÃ©menter circuit breaker (marquer provider unhealthy aprÃ¨s N Ã©checs)
2. Ajouter mÃ©triques de coÃ»t estimÃ©
3. Phase 3: Router LLM-based avec Qwen local
4. Tests de charge
